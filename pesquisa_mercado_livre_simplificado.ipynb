{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a raspagem do Mercado Livre, foi utilizado um código para a primeira página e copiado para gerar da segunda página em diante. \n",
    "Na verdade a estrutura do codigo são iguais a mudança ocorre na construção da url.\n",
    "\n",
    "Assim, este notebook foi divido colocando um bloco de código para cada termo pesquisado (brinquedo, escritório..) e dentro deste bloco um bloco para a primeira página e outro para as páginas seguintes (página 2 em diante).\n",
    "\n",
    "As funções de extrair primeira página e páginas seguintes não foram terminadas, o que deixaria o código mais enxuto e legível.\n",
    "\n",
    "A função extrai_valor_parcelas esta em aplicação, ela é usada após a raspagem para tratar a coluna Parcelas que na extração possui a quantidade de parcelas e o valor juntos, esta função cria mais 2 colunas com estes respectivos valores.\n",
    "\n",
    "\n",
    "## URL de pesquisa\n",
    "A estrututa do url da primeira página é simples: composto pela url da homepage mais o item pesquisado conforme abaixo:\n",
    "\n",
    "homepage  = \"https://lista.mercadolivre.com.br/\"\n",
    "item pesquisa = 'brinquedo'\n",
    "url da pesquisa = \"{homepage}{item}#D[A:{item}]\"\n",
    "\n",
    "Exemplo: https://lista.mercadolivre.com.br/notebook#D[A:notebook]\n",
    "\n",
    "Nas paginas seguintes a estrutura muda, é inserido na estrutura a categoria do item, sendo necessário pesquisar previamente, e o número da páginas dentro do url segue um adrão diferente para cada pesquisa. Exemplo, na segunda página, aparece dentro da url  o número 49 e as para as páginas seguintes soma-se 48. Mas, para outros termos a segunda página pode ser 50, e as seguintes soma-se 51. Assim, é necessário uma pesquisa anterior para realizar a raspagem. Mas, a estrutura das urls seguem estes padrões.\n",
    "Segue exemplos abaixo:\n",
    "\n",
    "página 2 da pesquisa de brinquedo: https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_49_NoIndex_True  \n",
    "página 3: https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_97_NoIndex_True\n",
    "\n",
    "\n",
    "Os códigos apresentam breves comentarios para melhor entendimento.\n",
    "\n",
    "\n",
    "## Patrocinados\n",
    "\n",
    "Os produtos patrocinados aparecem em cada página, e estão em uma classe do código html diferente dos produtos normais, assim, dentro do bloco de código da Primeira página e de Páginas seguintes a primeira raspagem são nestes produtos e depois nos normais. \n",
    "\n",
    "\n",
    "# COMO PESQUISAR NESTA RASPAGEM\n",
    "\n",
    "- Rodar a célula de importação de bibliotecas e da função extrai_valor_parcelas\n",
    "\n",
    "- Na célula da Raspagem:\n",
    "    - alterar a variável 'item' para o termo que deseja ser pesquisado\n",
    "    - (se necessário) alterar a variavel 'n' para o numero que aparece na url da pagina 2 (ver URL de pesquisa mais acima).\n",
    "    - (se necessário) alterar a variável incremento, verificar o incremento da url da pagina 2 para pagina 3.\n",
    "    * Obs. A maioria dos itens pesquisados o n é 49 e incremento 48, mas pode haver pesquisa que n é 51 e incremento 50.\n",
    "    - alterar a variável 'search_url2' para a url da página 2, dentro desta url trocar o numero 49 (ou 51, algumas vezes) para {n} (letra n entre chaves).\n",
    "    - alterar a variavel 'caminho' para o endereço da pasta e nome do arquivo xlsx que ficará salvo a planilha.\n",
    "\n",
    "Pronto! Rodar todas as células, depois de alguns minutos o arquivo xlsx aparecerá na pasta indicada no 'caminho'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# função que separa o conteudo da coluna Parcelas (numero de parcelas e valor)\n",
    "# e realiza a conta do valor total das parcelas\n",
    "\n",
    "def extrai_valor_parcelas(df):\n",
    "\n",
    "    # separa o valor de parcela utilizando expressão regular. extrai o valor com virgula que constam após o R$\n",
    "    df['Valor Parcelas'] = df['Parcelas'].str.extract(r'R\\$(\\d+,\\d+)')\n",
    "    df['Valor Parcelas'] = df['Valor Parcelas'].fillna(0)\n",
    "    df['Valor Parcelas'] = df['Valor Parcelas'].apply(lambda x: float(str(x).replace(',', '.')))\n",
    "\n",
    "    # as parcelas aparecem ao lado da letra x como: '12x'\n",
    "    # expressão que separa o numeros seguidos por 'x' \n",
    "    df['N Parcelas'] = df['Parcelas'].str.extract(r'(\\d+)x')\n",
    "    df['N Parcelas'] = df['N Parcelas'].fillna(0)\n",
    "    df['N Parcelas'] = df['N Parcelas'].apply(lambda x: int(x))\n",
    "\n",
    "    df[' Total parcelas'] = df['Valor Parcelas'] * df['N Parcelas']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ALTERAR para o item que deseja buscar\n",
    "item = 'meias'\n",
    "\n",
    "# numero do url pagina 2\n",
    "n = 49 \n",
    "\n",
    "# incremento por pagina\n",
    "incremento = 48\n",
    "\n",
    "## ALTERAR o url da pagina 2, e no lugar do numero 49 colocar {n}\n",
    "search_url2 = f'https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_{n}_AGE*GROUP_6725189_NoIndex_True'\n",
    "\n",
    "\n",
    "## ALTERAR o caminho para exportat como planilha excel\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\teste.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "    \n",
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "\n",
    "\n",
    "if ' ' in item:\n",
    "    search_url = f\"{base_url}{item.replace(' ', '-')}#D[A:{item.replace(' ', '%20')}]\"\n",
    "\n",
    "else:\n",
    "    search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML \n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Classe html dos produtos normais\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "# todos os produtos tem essa classe, então usa-se o find all para trazer todos\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "# Lista para armazenar os dados dos produtos patrocinados\n",
    "products_data_patr = []\n",
    "\n",
    "# Lista para armazenar os dados dos produtos normais\n",
    "products_data = []\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# Classe html dos produtos patrocinados\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "\n",
    "df_patr = pd.DataFrame()\n",
    "\n",
    "if products_patr !=  None:\n",
    "    \n",
    "    products_patr = products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number').text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "        except:\n",
    "            product_qt_eval = ''\n",
    "        \n",
    "           \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            product_discount = ''\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href que está o link do produto\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            \n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ##############################################################################################\n",
    "        # posição de venda na categoria, se possui\n",
    "    \n",
    "        \n",
    "        position = soup2.find('div', class_ = 'ui-pdp-container__col col-1 ui-pdp-container--column-right mt-16 pr-16 ui-pdp--relative')\n",
    "        if position.find('div', class_ = 'ui-pdp-container__row ui-pdp-container__row--highlights') != None:\n",
    "            \n",
    "            position = position.find_all('a', class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "        else:\n",
    "            position = ''\n",
    "                \n",
    " \n",
    "\n",
    "            \n",
    "        # Frete\n",
    "        try:\n",
    "            product_fret = soup2.find('p', class_ = 'ui-pdp-color--GREEN ui-pdp-family--SEMIBOLD ui-pdp-media__title').text\n",
    "            \n",
    "        except:\n",
    "            product_fret = ''\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            \n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "            # Quant. de fotos e data foto\n",
    "        try:\n",
    "            \n",
    "            # grade que estao as fotos\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "            \n",
    "            \n",
    "            # quantidade de fotos\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # data da foto\n",
    "            \n",
    "        date_image = soup2.find('figure', class_ = 'ui-pdp-gallery__figure')\n",
    "        \n",
    "        #date_image = date_image.find('img')\n",
    "        \n",
    "        date_image = re.findall(r'https://\\S+', str(date_image))[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    #CATEGORIAS\n",
    "    ##########################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "        \n",
    "        \n",
    "        patrocinado = 'sim'\n",
    "    ###############################################\n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': patrocinado, \n",
    "                            'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                            'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                            'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                            'Categorias': categories_list,'Quant. fotos': images, 'HTML Data': date_image})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "    df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    # se patrocinado caso, pagina seja com produtos na vertical\n",
    "    product_patr = products[i].find('label', class_='ui-search-styled-label ui-search-item__pub-label')\n",
    "    \n",
    "\n",
    "    \n",
    "    if product_patr == None:\n",
    "        patrocinado = 'nao'\n",
    "\n",
    "    else:\n",
    "        patrocinado = 'sim'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        product_discount = ''\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # posição de venda na categoria, se possui\n",
    "    \n",
    "   \n",
    "    position = soup2.find('div', class_ = 'ui-pdp-container__col col-1 ui-pdp-container--column-right mt-16 pr-16 ui-pdp--relative')\n",
    "    if position.find('div', class_ = 'ui-pdp-container__row ui-pdp-container__row--highlights') != None:\n",
    "        \n",
    "        position = position.find_all('a', class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "    else:\n",
    "        position = ''\n",
    "            \n",
    "    \n",
    "\n",
    "    # Frete\n",
    "    try:\n",
    "        product_fret = soup2.find('p', class_ = 'ui-pdp-color--GREEN ui-pdp-family--SEMIBOLD ui-pdp-media__title').text\n",
    "        \n",
    "    except:\n",
    "        product_fret = ''\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "     # data da foto\n",
    "            \n",
    "    date_image = soup2.find('figure', class_ = 'ui-pdp-gallery__figure')\n",
    "    \n",
    "    \n",
    "    \n",
    "    date_image = re.findall(r'https://\\S+', str(date_image))[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # categorias\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': patrocinado, \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images, 'HTML Data': date_image})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prpau\\AppData\\Local\\Temp\\ipykernel_13620\\49187481.py:448: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mercado_brinquedo[f'Categoria{x}'].iloc[i] = df_mercado_brinquedo['Categorias'].iloc[i][x]\n"
     ]
    }
   ],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    \n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url2)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    \n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    \n",
    "\n",
    "    if products_patr !=  None:\n",
    "        \n",
    "        products_patr = products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "        for x in range(len(products_patr)):\n",
    "\n",
    "            \n",
    "            # Obtém o nome do produto\n",
    "            product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "            \n",
    "            # Obtém o preço do produto\n",
    "            product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "            try:\n",
    "            # avaliação\n",
    "                product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "            # qtde avaliações\n",
    "                product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #frete gratis\n",
    "            try:\n",
    "                product_fret = products_patr[x].find('span', class_='ui-pb-highlight').text.striP()\n",
    "            except:\n",
    "                product_fret = ''    \n",
    "\n",
    "            try: \n",
    "                # parcelas\n",
    "                product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "                # Extrai o texto do elemento\n",
    "                product_parc = product_parc.get_text(strip=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # sem juros    \n",
    "            try:\n",
    "                product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "                product_juros = product_juros.find(text='juros')\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                # desconto\n",
    "            try:\n",
    "                product_discount = products_patr[x].find('span', class_='ui-search-price__discount').text.strip()\n",
    "            except:\n",
    "                product_discount = ''\n",
    "\n",
    "\n",
    "            #link\n",
    "            product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "            # Extrai o atributo href do elemento\n",
    "            product_link = product_link['href']\n",
    "\n",
    "\n",
    "            # DADOS LINK\n",
    "\n",
    "            response2 = requests.get(product_link)\n",
    "\n",
    "            # Verifica se a requisição foi bem-sucedida\n",
    "            if response2.status_code != 200:\n",
    "                print(f\"Erro ao acessar a URL: {product_link}\")\n",
    "\n",
    "            # Parsing do HTML\n",
    "            soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "            # Nome vendedor\n",
    "            try:\n",
    "                #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "                info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "                # Extrai o vendedor \n",
    "                seller = info_element.text\n",
    "\n",
    "            except:\n",
    "                seller= ''\n",
    "\n",
    "            # posição de venda na categoria, se possui\n",
    "            \n",
    "            try:\n",
    "                position = soup2.find('div', class_ = 'ui-pdp-container__col col-1 ui-pdp-container--column-right mt-16 pr-16 ui-pdp--relative')\n",
    "                if position.find('div', class_ = 'ui-pdp-container__row ui-pdp-container__row--highlights') != None:\n",
    "                    \n",
    "                    position = position.find_all('a', class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "                    position = position[1].text\n",
    "                else:\n",
    "                    position = ''\n",
    "                    \n",
    "            except:\n",
    "                position = ''\n",
    "\n",
    "            # Frete\n",
    "            try:\n",
    "                product_fret = soup2.find('p', class_ = 'ui-pdp-color--GREEN ui-pdp-family--SEMIBOLD ui-pdp-media__title').text\n",
    "                \n",
    "            except:\n",
    "                product_fret = ''\n",
    "\n",
    "\n",
    "            try:\n",
    "            # Novo/usado e qtde vendida\n",
    "                #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "                situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "                # Separa as informações 'Novo' e '+500 vendidos'\n",
    "                info_parts = situation.text.split('|')\n",
    "\n",
    "                # Remove os espaços em branco ao redor de cada parte\n",
    "                info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "                product_situation = info_parts[0]\n",
    "                product_sells = info_parts[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "                # Quant. de fotos\n",
    "            try:\n",
    "                # qtde fotos\n",
    "                #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "                #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "                #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "                images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "                images = len(images)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            \n",
    "             # data da foto\n",
    "            date_image = soup2.find('figure', class_ = 'ui-pdp-gallery__figure')\n",
    "            \n",
    "            #date_image = date_image.find('img')\n",
    "            \n",
    "            date_image = re.findall(r'https://\\S+', str(date_image))\n",
    "\n",
    "\n",
    "\n",
    "            # categorias\n",
    "            data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "            categories_list = []\n",
    "            \n",
    "\n",
    "            for cat in data_top:\n",
    "\n",
    "                cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "                categories_list.append(cat['title'])\n",
    "        \n",
    "    ###############################################\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "            patrocinado = 'sim'\n",
    "            \n",
    "            # Adiciona os dados do produto à lista\n",
    "            all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': patrocinado, \n",
    "                            'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                            'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                            'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                            'Categorias': categories_list,'Quant. fotos': images, 'HTML Data': date_image})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "        patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "        all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################################################3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        #preço\n",
    "        try:\n",
    "            product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "        except:\n",
    "            product_price = product.find('span', class_='andes-money-amount__fraction').text.strip()\n",
    "\n",
    "\n",
    "        # se patrocinado caso, pagina seja com produtos na vertical\n",
    "        product_patr = products[i].find('label', class_='ui-search-styled-label ui-search-item__pub-label')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        if product_patr == None:\n",
    "            patrocinado = 'nao'\n",
    "            \n",
    "        else:\n",
    "            patrocinado = 'sim'\n",
    "            \n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            product_fret = ''    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            product_discount = ''\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "    \n",
    "        try:\n",
    "            position = soup2.find('div', class_ = 'ui-pdp-container__col col-1 ui-pdp-container--column-right mt-16 pr-16 ui-pdp--relative')\n",
    "            if position.find('div', class_ = 'ui-pdp-container__row ui-pdp-container__row--highlights') != None:\n",
    "                \n",
    "                position = position.find_all('a', class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "                position = position[1].text\n",
    "\n",
    "            else:\n",
    "                position = ''\n",
    "                \n",
    "        except:\n",
    "            position = ''\n",
    "\n",
    "        # Frete\n",
    "        try:\n",
    "            product_fret = soup2.find('p', class_ = 'ui-pdp-color--GREEN ui-pdp-family--SEMIBOLD ui-pdp-media__title').text\n",
    "            \n",
    "        except:\n",
    "            product_fret = ''\n",
    "            \n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         # data da foto\n",
    "            \n",
    "        date_image = soup2.find('figure', class_ = 'ui-pdp-gallery__figure')\n",
    "        \n",
    "        #date_image = date_image.find('img')\n",
    "        \n",
    "        date_image = re.findall(r'https://\\S+', str(date_image))\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "        # categorias\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': patrocinado, \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images, 'HTML Data': date_image})\n",
    "\n",
    "\n",
    "\n",
    "####    # Incrementa a posição conforme a página seguinte\n",
    "    \n",
    "    n = n + incremento\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# juntando os dataframes\n",
    "df_mercado_brinquedo = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_brinquedo = extrai_valor_parcelas(df_mercado_brinquedo)\n",
    "df_mercado_brinquedo.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "\n",
    "df_mercado_brinquedo['Categoria'] = item\n",
    "\n",
    "\n",
    "\n",
    "df_mercado_brinquedo['Categoria0'] = 0\n",
    "df_mercado_brinquedo['Categoria1'] = 0\n",
    "df_mercado_brinquedo['Categoria2'] = 0\n",
    "df_mercado_brinquedo['Categoria3'] = 0\n",
    "df_mercado_brinquedo['Categoria4'] = 0\n",
    "df_mercado_brinquedo['Categoria5'] = 0\n",
    "df_mercado_brinquedo['Categoria6'] = 0\n",
    "\n",
    "for i in range(len(df_mercado_brinquedo['Categorias'])):\n",
    "\n",
    "    for x in range(len(df_mercado_brinquedo['Categorias'].iloc[i])):\n",
    "        df_mercado_brinquedo[f'Categoria{x}'].iloc[i] = df_mercado_brinquedo['Categorias'].iloc[i][x]\n",
    "\n",
    "        \n",
    "        \n",
    "for i in range(len(df_mercado_brinquedo['Categorias'])):\n",
    "\n",
    "        for x in range(1,7):\n",
    "            if df_mercado_brinquedo[f'Categoria{x}'].iloc[i] == 0:\n",
    "                df_mercado_brinquedo[f'Categoria{x}'].iloc[i] = df_mercado_brinquedo[f'Categoria{x-1}'].iloc[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Exportando o dataframe para planlha excel\n",
    "df_mercado_brinquedo.to_excel(caminho, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exportando o dataframe para planlha excel\n",
    "df_mercado_brinquedo.to_excel(caminho, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4ff7311eafac93b92f21d9a2329e46afd84871b50c290fea5610f23becc04a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
