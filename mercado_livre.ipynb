{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a raspagem do Mercado Livre, foi utilizado um código para a primeira página e copiado para gerar da segunda página em diante. \n",
    "Na verdade a estrutura do codigo são iguais a mudança ocorre na construção da url.\n",
    "\n",
    "Assim, este notebook foi divido colocando um bloco de código para cada termo pesquisado (brinquedo, escritório..) e dentro deste bloco um bloco para a primeira página e outro para as páginas seguintes (página 2 em diante).\n",
    "\n",
    "As funções de extrair primeira página e páginas seguintes não foram terminadas, o que deixaria o código mais enxuto e legível.\n",
    "\n",
    "A função extrai_valor_parcelas esta em aplicação, ela é usada após a raspagem para tratar a coluna Parcelas que na extração possui a quantidade de parcelas e o valor juntos, esta função cria mais 2 colunas com estes respectivos valores.\n",
    "\n",
    "\n",
    "## URL de pesquisa\n",
    "A estrututa do url da primeira página é simples: composto pela url da homepage mais o item pesquisado conforme abaixo:\n",
    "\n",
    "homepage  = \"https://lista.mercadolivre.com.br/\"\n",
    "item pesquisa = 'brinquedo'\n",
    "url da pesquisa = \"{homepage}{item}#D[A:{item}]\"\n",
    "\n",
    "Exemplo: https://lista.mercadolivre.com.br/notebook#D[A:notebook]\n",
    "\n",
    "Nas paginas seguintes a estrutura muda, é inserido na estrutura a categoria do item, sendo necessário pesquisar previamente, e o número da páginas dentro do url segue um adrão diferente para cada pesquisa. Exemplo, na segunda página, aparece dentro da url  o número 49 e as para as páginas seguintes soma-se 48. Mas, para outros termos a segunda página pode ser 50, e as seguintes soma-se 51. Assim, é necessário uma pesquisa anterior para realizar a raspagem. Mas, a estrutura das urls seguem estes padrões.\n",
    "Segue exemplos abaixo:\n",
    "\n",
    "página 2 da pesquisa de brinquedo: https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_49_NoIndex_True  \n",
    "página 3: https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_97_NoIndex_True\n",
    "\n",
    "\n",
    "Os códigos apresentam breves comentarios para melhor entendimento.\n",
    "\n",
    "\n",
    "## Patrocinados\n",
    "\n",
    "Os produtos patrocinados aparecem em cada página, e estão em uma classe do código html diferente dos produtos normais, assim, dentro do bloco de código da Primeira página e de Páginas seguintes a primeira raspagem são nestes produtos e depois nos normais. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# função que separa o conteudo da coluna Parcelas (numero de parcelas e valor)\n",
    "# e realiza a conta do valor total das parcelas\n",
    "\n",
    "def extrai_valor_parcelas(df):\n",
    "\n",
    "    # separa o valor de parcela utilizando expressão regular. extrai o valor com virgula que constam após o R$\n",
    "    df['Valor Parcelas'] = df['Parcelas'].str.extract(r'R\\$(\\d+,\\d+)')\n",
    "    df['Valor Parcelas'] = df['Valor Parcelas'].fillna(0)\n",
    "    df['Valor Parcelas'] = df['Valor Parcelas'].apply(lambda x: float(str(x).replace(',', '.')))\n",
    "\n",
    "    # as parcelas aparecem ao lado da letra x como: '12x'\n",
    "    # expressão que separa o numeros seguidos por 'x' \n",
    "    df['N Parcelas'] = df['Parcelas'].str.extract(r'(\\d+)x')\n",
    "    df['N Parcelas'] = df['N Parcelas'].fillna(0)\n",
    "    df['N Parcelas'] = df['N Parcelas'].apply(lambda x: int(x))\n",
    "\n",
    "    df[' Total parcelas'] = df['Valor Parcelas'] * df['N Parcelas']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função Extrai primeira página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função extrai primeira página\n",
    "\n",
    "def extrai_primeira_pagina(item):\n",
    "\n",
    "    base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "    \n",
    "    search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos\n",
    "    products_data = []\n",
    "\n",
    "    products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for i in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "        except:\n",
    "            product_qt_eval = ''\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            product_fret = ''    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            product_discount = ''\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "    ###############################################\n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                            'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                            'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                            'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, 'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "    df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "    \n",
    "    #############################################################\n",
    "    # Produtos nao patrocinados\n",
    "\n",
    "    for i in range(len(products)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "            \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "    ###############################################\n",
    "\n",
    "        # patrocinado\n",
    "        try:\n",
    "        \n",
    "            patrocinado = products[i].find('div', class_='ui-search-styled-label ui-search-item__pub-label').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'não', \n",
    "                            'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                            'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                            'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, 'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "    df = pd.DataFrame(products_data)\n",
    "\n",
    "\n",
    "    return df_patr, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brinquedos-hobbies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função extrai paginas seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_paginas_seguintes(item, categorias: list):\n",
    "\n",
    "    # DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "    all_products_df = pd.DataFrame()\n",
    "    all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        n = 49 \n",
    "\n",
    "        if len(categorias) == 1:\n",
    "            search_url = f'https://lista.mercadolivre.com.br/{categorias[0]}/{item}{n}_NoIndex_True'\n",
    "\n",
    "        else:\n",
    "            search_url = f'https://lista.mercadolivre.com.br/{categorias[0]}/{categorias[1]}/{item}_Desde_49_NoIndex_True'\n",
    "\n",
    "        # Realiza a requisição HTTP\n",
    "        response = requests.get(search_url)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "            continue\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Lista para armazenar os dados dos produtos desta iteração\n",
    "        products_data = []\n",
    "\n",
    "        # Encontra os elementos que contêm as informações do produto\n",
    "        products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        all_products_data_patr = []\n",
    "\n",
    "\n",
    "        # produtos patrocinados\n",
    "        products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "        products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "        for x in range(len(products_patr)):\n",
    "\n",
    "            \n",
    "            # Obtém o nome do produto\n",
    "            product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "            \n",
    "            # Obtém o preço do produto\n",
    "            product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "            try:\n",
    "            # avaliação\n",
    "                product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "            # qtde avaliações\n",
    "                product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #frete gratis\n",
    "            try:\n",
    "                product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "            except:\n",
    "                pass    \n",
    "\n",
    "            try: \n",
    "                # parcelas\n",
    "                product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "                # Extrai o texto do elemento\n",
    "                product_parc = product_parc.get_text(strip=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # sem juros    \n",
    "            try:\n",
    "                product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "                product_juros = product_juros.find(text='juros')\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "                # desconto\n",
    "            try:\n",
    "                product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            #link\n",
    "            product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "            # Extrai o atributo href do elemento\n",
    "            product_link = product_link['href']\n",
    "\n",
    "\n",
    "            # DADOS LINK\n",
    "\n",
    "            response2 = requests.get(product_link)\n",
    "\n",
    "            # Verifica se a requisição foi bem-sucedida\n",
    "            if response2.status_code != 200:\n",
    "                print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "            # Parsing do HTML\n",
    "            soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "            # Nome vendedor\n",
    "            try:\n",
    "                #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "                info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "                # Extrai o vendedor \n",
    "                seller = info_element.text\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            # posição de venda na categoria, se possui\n",
    "            try:\n",
    "\n",
    "                #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "                #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "                position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "                position = position[1].text\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "            try:\n",
    "            # Novo/usado e qtde vendida\n",
    "                #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "                situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "                # Separa as informações 'Novo' e '+500 vendidos'\n",
    "                info_parts = situation.text.split('|')\n",
    "\n",
    "                # Remove os espaços em branco ao redor de cada parte\n",
    "                info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "                product_situation = info_parts[0]\n",
    "                product_sells = info_parts[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "                # Quant. de fotos\n",
    "            try:\n",
    "                # qtde fotos\n",
    "                #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "                #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "                #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "                images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "                images = len(images)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "        ###############################################\n",
    "\n",
    "            \n",
    "            # Adiciona os dados do produto à lista\n",
    "            all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                                'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                                'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                                'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, 'Quant. fotos': images})\n",
    "\n",
    "        # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "        patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "        all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for product in products:\n",
    "            # Obtém o nome do produto\n",
    "            product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "            # Obtém o preço do produto\n",
    "            product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "            try:\n",
    "        # avaliação\n",
    "                product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "            # qtde avaliações\n",
    "                product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            #frete gratis\n",
    "            try:\n",
    "                product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "            except:\n",
    "                pass    \n",
    "\n",
    "\n",
    "            try: \n",
    "            # parcelas\n",
    "                product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "                # Extrai o texto do elemento\n",
    "                product_parc = product_parc.get_text(strip=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # sem juros    \n",
    "            try:\n",
    "                product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "                product_juros = product_juros.find(text='juros')\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            # desconto\n",
    "            try:\n",
    "                product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "            except:\n",
    "                product_discount = ''\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            #link\n",
    "            product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "            # Extrai o atributo href do elemento\n",
    "            product_link = product_link['href']\n",
    "\n",
    "\n",
    "            # DADOS LINK\n",
    "\n",
    "            response2 = requests.get(product_link)\n",
    "\n",
    "            # Verifica se a requisição foi bem-sucedida\n",
    "            if response2.status_code != 200:\n",
    "                print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "            # Parsing do HTML\n",
    "            soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "            # Vendedor\n",
    "            try:\n",
    "                #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "                #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "                info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "                # Extrai o texto do elemento\n",
    "                seller = info_element\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "            # posição de venda na categoria, se possui\n",
    "            try:\n",
    "\n",
    "                #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "                #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "                #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "                position = soup2[1].text\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "                # Novo/usado e qtde vendida\n",
    "            try:\n",
    "            \n",
    "                #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "                situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "                # Separa as informações 'Novo' e '+500 vendidos'\n",
    "                info_parts = situation.text.split('|')\n",
    "\n",
    "                # Remove os espaços em branco ao redor de cada parte\n",
    "                info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "                product_situation = info_parts[0]\n",
    "                product_sells = info_parts[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "                # Quant. de fotos\n",
    "            try:\n",
    "                \n",
    "                #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "                #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "                #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "                images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "                images = len(images)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    ################################################\n",
    "\n",
    "            patrocinado_tag = product.find('label', class_='ui-search-styled-label.ui-search-item__pub-label')\n",
    "            patrocinado = patrocinado_tag.text.strip() if patrocinado_tag else \"Não disponível\"\n",
    "\n",
    "            # Adiciona os dados do produto à lista\n",
    "            products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': patrocinado, \n",
    "                            'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc,\n",
    "                            'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                            'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, 'Quant. fotos': images})\n",
    "\n",
    "        n = n + 48\n",
    "        # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "        temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "        # Concatena o DataFrame temporário ao DataFrame principal\n",
    "        all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)\n",
    "\n",
    "        return all_products_df_patr, all_products_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brinquedos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'brinquedo'\n",
    "\n",
    "\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML \n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Classe html dos produtos normais\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "# todos os produtos tem essa classe, então usa-se o find all para trazer todos\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "# Lista para armazenar os dados dos produtos patrocinados\n",
    "products_data_patr = []\n",
    "\n",
    "# Lista para armazenar os dados dos produtos normais\n",
    "products_data = []\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# Classe html dos produtos patrocinados\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href que está o link do produto\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        \n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        \n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        \n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        \n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "    \n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Páginas seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_49_NoIndex_True\n"
     ]
    }
   ],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/brinquedos-hobbies/brinquedo_Desde_{n}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "\n",
    "\n",
    "####    # Incrementa a posição conforme a págin seguinte\n",
    "    \n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# juntando os dataframes\n",
    "df_mercado_brinquedo = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_brinquedo = extrai_valor_parcelas(df_mercado_brinquedo)\n",
    "df_mercado_brinquedo.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_brinquedo['Preço'] = df_mercado_brinquedo['Preço'].apply(lambda x: float(x.replace('R$', '').replace(',', '.')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\brinquedos_mercadolivre.xlsx'\n",
    "df_mercado_brinquedo.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escritório"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'escritorio'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paginas Seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/casa-moveis-decoracao/escritorio_Desde_{n}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntando os dataframes\n",
    "df_mercado_escritorio = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_escritorio = extrai_valor_parcelas(df_mercado_escritorio)\n",
    "df_mercado_escritorio.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_escritorio['Qtde avaliações:'] = df_mercado_escritorio['Qtde avaliações:'].apply(lambda x: int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_escritorio['Preço'] = df_mercado_escritorio['Preço'].apply(lambda x: float(x.replace('R$', '').replace(',', '.')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\escritorio_mercadolivre.xlsx'\n",
    "df_mercado_escritorio.to_excel(caminho, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mochila"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'mochila'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paginas Seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/calcados-roupas-bolsas/malas-bolsas/mochilas/mochila_Desde_{n}_AGE*GROUP_6725189_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_mochila = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_mochila = extrai_valor_parcelas(df_mercado_mochila)\n",
    "df_mercado_mochila.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_mochila['Qtde avaliações:'] = df_mercado_mochila['Qtde avaliações:'].apply(lambda x: int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_mochila['Preço'] = df_mercado_mochila['Preço'].apply(lambda x: float(x.replace('R$', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\mochila_mercadolivre.xlsx'\n",
    "df_mercado_mochila.to_excel(caminho, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisa para mais de uma palavra\n",
    "def formatar_para_url2(string):\n",
    "    # Substitui os espaços por \"%20\"\n",
    "    return string.replace(\" \", \"%20\")\n",
    "\n",
    "def formatar_para_url1(string):\n",
    "    # Substitui os espaços por \"%20\"\n",
    "    return string.replace(\" \", \"-\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papelaria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'papelaria'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Páginas Seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/arte-papelaria-armarinho/materiais-escolares/papelaria_Desde_{n}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_papelaria = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_papelaria = extrai_valor_parcelas(df_mercado_papelaria)\n",
    "df_mercado_papelaria.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "#df_mercado_papelaria['Qtde avaliações:'] = df_mercado_papelaria['Qtde avaliações:'].apply(lambda x: int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_papelaria['Preço'] = df_mercado_papelaria['Preço'].apply(lambda x: float(x.replace('R$', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\papelaria_mercadolivre.xlsx'\n",
    "df_mercado_papelaria.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'pc'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    #data_top = soup2.find('div',class_='ui-pdp')\n",
    "    #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "    #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        #data_top = soup2.find('div',class_='ui-pdp')\n",
    "        #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "        #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    except:\n",
    "        categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paginas seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/informatica/pc-mesa/computadores/pc_Desde_{n}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            #data_top = soup2.find('div',class_='ui-pdp')\n",
    "            #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "            #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "            data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "            categories_list = []\n",
    "            \n",
    "\n",
    "            for cat in data_top:\n",
    "\n",
    "                categories_list.append(cat.text)\n",
    "        except:\n",
    "             categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        try:\n",
    "            #data_top = soup2.find('div',class_='ui-pdp')\n",
    "            #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "            #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "            data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "            categories_list = []\n",
    "            \n",
    "\n",
    "            for cat in data_top:\n",
    "\n",
    "                categories_list.append(cat.text)\n",
    "        except:\n",
    "             categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_pc = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_pc = extrai_valor_parcelas(df_mercado_pc)\n",
    "df_mercado_pc.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_pc['Qtde avaliações:'] = df_mercado_pc['Qtde avaliações:'].apply(lambda x: x if x == '' else int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_pc['Preço'] = df_mercado_pc['Preço'].apply(lambda x: float(x.replace('R$', '').replace('.', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\pc_mercadolivre.xlsx'\n",
    "df_mercado_pc.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeira Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'notebook'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        product_juros = ''\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        product_discount = ''\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    #data_top = soup2.find('div',class_='ui-pdp')\n",
    "    #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "    #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "    #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "        #data_top = soup2.find('div',class_='ui-pdp')\n",
    "        #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "        #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "        #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    except:\n",
    "        categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Páginas seguintes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Ideapad 1 I3 8gb 256gb W11 Home 15.6 82vy000sbr\n",
      "2.480\n",
      "MacBook Air M2 2022 midnight 13.6\", Apple M2  8GB de RAM 256GB SSD, Apple M2 10-Core GPU 2560x1664px macOS\n",
      "8.199\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Cinza-espacial\n",
      "5.943\n",
      "Notebook Dell Latitude E5450 Core I5  16 Gb Ram  480 Gb Ssd\n",
      "1.799\n",
      "Notebook Aspire 5 A515-57-58w1 I5 Linux 8gb 256gb 15,6' Fhd\n",
      "3.559\n",
      "Notebook Loq I5-12450h 16gb 512gb Ssd Rtx 3050 15.6 Fhd W11\n",
      "5.799\n",
      "Notebook Gamer Acer Nitro 5 17.3 144hz I5 512gb 8gb Rtx 3050 Cor Preto\n",
      "5.942\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i7-1255U 16GB 512GB SSD Windows 11 Home 15.6\" 82VY000NBR\n",
      "3.679\n",
      "Notebook Elitebook Hp 840 I5 6300u 16gb Ssd 256gb Win 11\n",
      "1.849\n",
      "Notebook Multi Ultra Celeron N4020c 4gb 128gb W11 15,6'' Cinza - Ub261\n",
      "2.256\n",
      "Notebook Acer Aspire A315-24p-r06b 8gb 512gb W11 15.6  Prata Cor Prateado\n",
      "2.699\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i3-1215U 4GB 256GB SSD Windows 11 Home 14\" 83AF0000BR\n",
      "1.919\n",
      "Notebook Galaxy Book Go Snapdragon 7c 14'' Full Hd Samsung Cor Prateado\n",
      "2.129\n",
      "Notebook Samsung Galaxy Book 2 Grafite I7 8gb Ram 256gb Ssd\n",
      "4.686\n",
      "Notebook Vaio® Fe15 Core I5-1235u 256gb Ssd Linux Debian\n",
      "2.733\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i5-1235U 8GB 512GB SSD Windows 11 Home 14\" 83AF000EBR\n",
      "2.789\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i3-1215U 4GB 256GB SSD Linux 14\" 83AFS00500\n",
      "1.849\n",
      "Notebook Gamer Acer An515-5759at I5 8gb 512gb Ssd 15.6'' W11 Cor Preto\n",
      "7.999\n",
      "Notebook Asus Celeron N4020 15.6 128gb W11h X515ma-br933ws\n",
      "1.655\n",
      "Notebook Vaio Fe15 Core I3 11ª 8 Gb 256 Gb Ssd 15,6'' W11 Grafite\n",
      "2.999\n",
      "Notebook Asus Vivobook 15x Oled Core I7 16gb 512ssd W11 15,6 Cor Preto\n",
      "6.157\n",
      "Notebook Acer Aspire 3 Core I3-n305 8gb 256gb Ram W11 15,6''\n",
      "3.099\n",
      "Notebook Dell Latitude 3470 Core I5 + 16 Gb Ram + 480 Gb Ssd\n",
      "1.999\n",
      "Notebook Ideapad 1 R3 8gb 256gb W11 15.6 82x5000abr\n",
      "2.029\n",
      "Notebook Vaio Fe15 Intel I5 1135g7 8gb Ssd 256gb 15,6  W11\n",
      "3.699\n",
      "Notebook ASUS Vivobook 16 I7 16GB 256GB 16\" W11 X1605ZA-MB312W\n",
      "4.399\n",
      "Notebook Samsung Chromebook XE310XBA prata 11.6\", Intel Celeron N4000  4GB de RAM 32GB SSD, Intel UHD Graphics 600 1366x768px Google Chrome\n",
      "1.533\n",
      "Notebook Asus Vivobook I5-12450h 4gb 256 Ssd 15,6'' W11\n",
      "3.499\n",
      "Notebook Samsung Book2 Np550xed-kf2br I5 8gb 256ssd 15.6 W11\n",
      "4.665\n",
      "Notebook ASUS Vivobook X1502ZA Intel Core i5 12450H 8GB Ram 256GB SSD Windows 11 Tela 15,6\" FHD Blue - EJ1755W\n",
      "2.599\n",
      "Notebook Asus M1502ia-ej251w R5 8gb 256gb W11 15,60  Fhd Cor Prateado\n",
      "2.599\n",
      "Notebook Loq I5-12450h 16gb 512gb Ssd Rtx 2050 15.6 Fhd W11\n",
      "4.429\n",
      "Notebook Acer Chromebook C733 preta 11.6\", Intel Celeron N4020  4GB de RAM 32GB SSD, Intel UHD Graphics 600 60 Hz 1366x768px Google Chrome\n",
      "2.069\n",
      "Notebook Gamer Lenovo Gaming 3i Intel Core i5-11300H GeForce GTX1650 8GB RAM SSD 512GB 15.6 Full HD Windows 11 Preto - 82MG0009BR\n",
      "7.329\n",
      "Notebook Positivo Vision I15 Lumina Bar 8gb 512gb Fhd W11 Cor Cinza\n",
      "4.499\n",
      "Notebook VAIO FE15 FE15 grafite 15.6\", Intel Core i5 1235U  8GB de RAM 512GB SSD, Intel UHD Graphics 60 Hz 1920x1080px Windows 11 Home\n",
      "3.197\n",
      "Galaxy Book2 Intel Core I3-1215u, 8gb, 256gb Ssd, 15.6\n",
      "2.799\n",
      "Notebook Compaq Intel I3 6157u 4gb Ssd 120gb\n",
      "1.759\n",
      "Notebook Dell Latitude 3480 Core I5 + 16 Gb Ram + 240 Gb Ssd\n",
      "1.874\n",
      "Notebook Dell Inspiron 3530 prateada 15.6\", Intel Core i7 1355U  16GB de RAM 1 TB SSD, NVIDIA GeForce MX550 120 Hz 1920x1080px Windows 11 Home\n",
      "6.656\n",
      "Notebook Hp 256-g9 I5 16gb 256gb Ssd Windows 11 8b3l7la Cor Preto\n",
      "5.999\n",
      "Notebook Gamer Legion Slim 5 I5 16gb 512gb Rtx 3050 W11 Home\n",
      "7.999\n",
      "Notebook Samsung Galaxy Book3 360 Intel Core I5 1335u, 16GB, 512GB SSD, Tela 13.3\", Windows11H - NP730QFG-KF1BR\n",
      "7.999\n",
      "Notebook Pense Bem Intel Celeron Win 11 Home  4gb 128gb Ssd Cor Unica\n",
      "1.349\n",
      "Notebook Predator Phn16-71-74ue Ci713° 16gb 1tbssd Rtx4060\n",
      "8.929\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Ouro\n",
      "5.943\n",
      "Notebook Dell Latitude E5470 I5 6th 8gb 240gb Ssd\n",
      "2.999\n",
      "Notebook Vaio Fe15 Ryzen 7 8gb 256gb 15'' Fhd Linux Cor Prata Titânio\n",
      "3.599\n",
      "Notebook Ideapad 1 I3 8gb 256gb W11 Home 15.6 82vy000sbr\n",
      "2.480\n",
      "MacBook Air M2 2022 midnight 13.6\", Apple M2  8GB de RAM 256GB SSD, Apple M2 10-Core GPU 2560x1664px macOS\n",
      "8.199\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Cinza-espacial\n",
      "5.948\n",
      "Notebook Dell Latitude E5450 Core I5  16 Gb Ram  480 Gb Ssd\n",
      "1.799\n",
      "Notebook Aspire 5 A515-57-58w1 I5 Linux 8gb 256gb 15,6' Fhd\n",
      "3.559\n",
      "Notebook Loq I5-12450h 16gb 512gb Ssd Rtx 3050 15.6 Fhd W11\n",
      "5.799\n",
      "Notebook Gamer Acer Nitro 5 17.3 144hz I5 512gb 8gb Rtx 3050 Cor Preto\n",
      "5.942\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i7-1255U 16GB 512GB SSD Windows 11 Home 15.6\" 82VY000NBR\n",
      "3.679\n",
      "Notebook Elitebook Hp 840 I5 6300u 16gb Ssd 256gb Win 11\n",
      "1.849\n",
      "Notebook Multi Ultra Celeron N4020c 4gb 128gb W11 15,6'' Cinza - Ub261\n",
      "2.256\n",
      "Notebook Acer Aspire A315-24p-r06b 8gb 512gb W11 15.6  Prata Cor Prateado\n",
      "2.699\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i3-1215U 4GB 256GB SSD Windows 11 Home 14\" 83AF0000BR\n",
      "1.919\n",
      "Notebook Galaxy Book Go Snapdragon 7c 14'' Full Hd Samsung Cor Prateado\n",
      "2.129\n",
      "Notebook Samsung Galaxy Book 2 Grafite I7 8gb Ram 256gb Ssd\n",
      "4.686\n",
      "Notebook Vaio® Fe15 Core I5-1235u 256gb Ssd Linux Debian\n",
      "2.733\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i5-1235U 8GB 512GB SSD Windows 11 Home 14\" 83AF000EBR\n",
      "2.789\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i3-1215U 4GB 256GB SSD Linux 14\" 83AFS00500\n",
      "1.849\n",
      "Notebook Gamer Acer An515-5759at I5 8gb 512gb Ssd 15.6'' W11 Cor Preto\n",
      "7.999\n",
      "Notebook Asus Celeron N4020 15.6 128gb W11h X515ma-br933ws\n",
      "1.655\n",
      "Notebook Vaio Fe15 Core I3 11ª 8 Gb 256 Gb Ssd 15,6'' W11 Grafite\n",
      "2.999\n",
      "Notebook Asus Vivobook 15x Oled Core I7 16gb 512ssd W11 15,6 Cor Preto\n",
      "6.157\n",
      "Notebook Acer Aspire 3 Core I3-n305 8gb 256gb Ram W11 15,6''\n",
      "3.099\n",
      "Notebook Dell Latitude 3470 Core I5 + 16 Gb Ram + 480 Gb Ssd\n",
      "1.999\n",
      "Notebook Ideapad 1 R3 8gb 256gb W11 15.6 82x5000abr\n",
      "2.029\n",
      "Notebook Vaio Fe15 Intel I5 1135g7 8gb Ssd 256gb 15,6  W11\n",
      "3.699\n",
      "Notebook ASUS Vivobook 16 I7 16GB 256GB 16\" W11 X1605ZA-MB312W\n",
      "4.399\n",
      "Notebook Samsung Chromebook XE310XBA prata 11.6\", Intel Celeron N4000  4GB de RAM 32GB SSD, Intel UHD Graphics 600 1366x768px Google Chrome\n",
      "1.533\n",
      "Notebook Asus Vivobook I5-12450h 4gb 256 Ssd 15,6'' W11\n",
      "3.499\n",
      "Notebook Samsung Book2 Np550xed-kf2br I5 8gb 256ssd 15.6 W11\n",
      "4.665\n",
      "Notebook ASUS Vivobook X1502ZA Intel Core i5 12450H 8GB Ram 256GB SSD Windows 11 Tela 15,6\" FHD Blue - EJ1755W\n",
      "2.599\n",
      "Notebook Asus M1502ia-ej251w R5 8gb 256gb W11 15,60  Fhd Cor Prateado\n",
      "2.599\n",
      "Notebook Loq I5-12450h 16gb 512gb Ssd Rtx 2050 15.6 Fhd W11\n",
      "4.429\n",
      "Notebook Acer Chromebook C733 preta 11.6\", Intel Celeron N4020  4GB de RAM 32GB SSD, Intel UHD Graphics 600 60 Hz 1366x768px Google Chrome\n",
      "2.069\n",
      "Notebook Gamer Lenovo Gaming 3i Intel Core i5-11300H GeForce GTX1650 8GB RAM SSD 512GB 15.6 Full HD Windows 11 Preto - 82MG0009BR\n",
      "7.329\n",
      "Notebook Positivo Vision I15 Lumina Bar 8gb 512gb Fhd W11 Cor Cinza\n",
      "4.499\n",
      "Notebook VAIO FE15 FE15 grafite 15.6\", Intel Core i5 1235U  8GB de RAM 512GB SSD, Intel UHD Graphics 60 Hz 1920x1080px Windows 11 Home\n",
      "3.197\n",
      "Galaxy Book2 Intel Core I3-1215u, 8gb, 256gb Ssd, 15.6\n",
      "2.799\n",
      "Notebook Compaq Intel I3 6157u 4gb Ssd 120gb\n",
      "1.759\n",
      "Notebook Dell Latitude 3480 Core I5 + 16 Gb Ram + 240 Gb Ssd\n",
      "1.874\n",
      "Notebook Dell Inspiron 3530 prateada 15.6\", Intel Core i7 1355U  16GB de RAM 1 TB SSD, NVIDIA GeForce MX550 120 Hz 1920x1080px Windows 11 Home\n",
      "6.656\n",
      "Notebook Hp 256-g9 I5 16gb 256gb Ssd Windows 11 8b3l7la Cor Preto\n",
      "5.999\n",
      "Notebook Gamer Legion Slim 5 I5 16gb 512gb Rtx 3050 W11 Home\n",
      "7.999\n",
      "Notebook Samsung Galaxy Book3 360 Intel Core I5 1335u, 16GB, 512GB SSD, Tela 13.3\", Windows11H - NP730QFG-KF1BR\n",
      "7.999\n",
      "Notebook Pense Bem Intel Celeron Win 11 Home  4gb 128gb Ssd Cor Unica\n",
      "1.349\n",
      "Notebook Predator Phn16-71-74ue Ci713° 16gb 1tbssd Rtx4060\n",
      "8.929\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Ouro\n",
      "5.943\n",
      "Notebook Dell Latitude E5470 I5 6th 8gb 240gb Ssd\n",
      "2.999\n",
      "Notebook Vaio Fe15 Ryzen 7 8gb 256gb 15'' Fhd Linux Cor Prata Titânio\n",
      "3.599\n",
      "Notebook Ideapad S145 Ryzen 5 8gb  15.6 Ssd 256 Promoçao\n",
      "1.930\n",
      "Notebook Dell Latitude 5300 2-em-1 I5 8ª 16g 256g Touch Fhd\n",
      "2.699\n",
      "Notebook Predator 72xa I7 12ª W11 Rtx3060 16gb 512gb Ssd 16\n",
      "9.099\n",
      "Notebook Acer Aspire A315-24p-r06b 8gb 512gb W11 15.6  Prata Cor Prateado\n",
      "2.699\n",
      "Notebook Positivo Vision I15 Lumina Bar 8gb 512gb Fhd W11 Cor Cinza\n",
      "4.499\n",
      "Notebook Samsung Book2 Np550xed-kf2br I5 8gb 256ssd 15.6 W11\n",
      "4.665\n",
      "Notebook Acer Aspire 3 Core I3-n305 8gb 256gb Ram W11 15,6''\n",
      "3.099\n",
      "Notebook Compuradora Hp 640 G2 Core I5/4gb/240gb Ssd/14 Hd Cor Preto\n",
      "1.906\n",
      "Ideapad Gaming 3i I7-11370h 16gb 512gb Ssd Gtx 1650 W11 Cor Shadow black\n",
      "4.499\n",
      "Notebook Dell Latitude 3470 Core I5 + 16 Gb Ram + 480 Gb Ssd\n",
      "1.999\n",
      "Notebook Dell Latitude 7430 Intel Core I7 12th 16gb 512 Ssd\n",
      "5.669\n",
      "Notebook Vaio Intel Core I3 8ger 8gb 240ssd 15pol - Vitrine\n",
      "2.099\n",
      "Notebook ASUS Vivobook 15 X1502ZA Intel Core i5 12450H 8Gb Ram 512 GB SSD Windows 11 Home Tela 15,60\" FHD Prata Metálico - EJ1777W\n",
      "3.035\n",
      "Galaxy Book2 Intel Core I3-1215u, 8gb, 256gb Ssd, 15.6\n",
      "2.799\n",
      "Notebook Vaio Fe15 Core I3 11ª 8 Gb 256 Gb Ssd 15,6'' W11 Grafite\n",
      "2.999\n",
      "Notebook Lenovo IdeaPad 1i Intel Core i7-1255U 16GB 512GB SSD Windows 11 Home 15.6\" 82VY000NBR\n",
      "3.679\n",
      "Notebook Dell Inspiron I15-i120k-a20pf I5 8gb 256gb W11 365\n",
      "3.199\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Cinza-espacial\n",
      "5.948\n",
      "Notebook Asus Vivobook 16 Intel Core I7 8gb 256ssd Keepos Cor Prateado\n",
      "2.979\n",
      "Notebook Asus Celeron N4020 15.6 128gb W11h X515ma-br933ws\n",
      "1.655\n",
      "Notebook Samsung Galaxy Book3 360 Intel Core I5 1335u, 16GB, 512GB SSD, Tela 13.3\", Windows11H - NP730QFG-KF1BR\n",
      "7.999\n",
      "Apple Macbook Air (13 polegadas, 2020, Chip M1, 256 GB de SSD, 8 GB de RAM) - Ouro\n",
      "5.943\n",
      "Notebook Acer Aspire 5 A515-57-55b8 Core I5 8gb 256ssd W11\n",
      "4.331\n",
      "Notebook Ideapad 1i I3 4gb 256gb Linux 15.6 82vys00600\n",
      "1.849\n",
      "Samsung Chromebook Intel Dual-core, 4gb, 64gb, 11.6\n",
      "1.839\n",
      "Notebook Asus Vivobook 16 Core I7 16gb 512ssd W11 16 Fhd Cor Prata metálico\n",
      "4.599\n",
      "Notebook Vaio Fe15 Intel I5 1135g7 8gb Ssd 256gb 15,6  W11\n",
      "3.699\n",
      "Notebook ASUS Vivobook X1502ZA Intel Core i5 12450H 8GB Ram 256GB SSD Windows 11 Tela 15,6\" FHD Blue - EJ1755W\n",
      "2.599\n",
      "Notebook Lenovo Ideapad 3i Celeron 4gb 128gb Ssd W11 15.6 Cor Prateado\n",
      "2.799\n",
      "Notebook 2 Em 1 Positivo Duo C4128b-3 4gb 128gb W11 Cor Cinza-escuro\n",
      "1.719\n",
      "Notebook Vaio® Fe15 Core I5-1235u 256gb Ssd Linux Debian\n",
      "2.733\n",
      "Notebook Lenovo Intel Core I5 8350u 8gb Ddr4 Ssd M.2 256gb\n",
      "2.045\n",
      "Notebook Samsung Galaxy Book 2 Grafite I7 8gb Ram 256gb Ssd\n",
      "4.686\n",
      "MacBook Air M2 2022 midnight 13.6\", Apple M2  8GB de RAM 256GB SSD, Apple M2 10-Core GPU 2560x1664px macOS\n",
      "8.199\n",
      "Notebook Hp 256-g9 I5 16gb 256gb Ssd Windows 11 8b3l7la Cor Preto\n",
      "5.999\n",
      "Notebook Ideapad 1 R3 8gb 256gb W11 15.6 82x5000abr\n",
      "2.029\n",
      "Notebook Acer Chromebook C733 preta 11.6\", Intel Celeron N4020  4GB de RAM 32GB SSD, Intel UHD Graphics 600 60 Hz 1366x768px Google Chrome\n",
      "2.069\n",
      "Notebook VAIO FE15 FE15 grafite 15.6\", Intel Core i5 1235U  8GB de RAM 512GB SSD, Intel UHD Graphics 60 Hz 1920x1080px Windows 11 Home\n",
      "3.197\n",
      "Notebook Pense Bem Intel Celeron Win 11 Home  4gb 128gb Ssd Cor Unica\n",
      "1.349\n",
      "Notebook Vaio® Fh15 Core I7 32gb 1tb Ssd Geforce Rtx® 3050 Cor Cinza Grafite\n",
      "10.999\n",
      "Notebook ASUS Vivobook 15 X1504ZA Intel Core i5 1235U 8GB Ram 512GB SSD Windows 11 Tela 15,6\" FHD Blue - NJ987W\n",
      "3.127\n"
     ]
    }
   ],
   "source": [
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/informatica/portateis-acessorios/notebooks/notebook_Desde_{n}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            #data_top = soup2.find('div',class_='ui-pdp')\n",
    "            #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "            #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "            data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "            categories_list = []\n",
    "            \n",
    "\n",
    "            for cat in data_top:\n",
    "\n",
    "                categories_list.append(cat.text)\n",
    "        except:\n",
    "             categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "\n",
    "        try:\n",
    "            product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "        except:\n",
    "            product_price = product.find('span', class_='andes-money-amount__fraction').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        try:\n",
    "            #data_top = soup2.find('div',class_='ui-pdp')\n",
    "            #data_top = soup2.find('div',class_='ui-pdp-container ui-pdp-container--top')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__row ui-pdp-group-header-breadcrumb')\n",
    "\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-container__col col-2')\n",
    "            #data_top = data_top.find('div', class_ = 'ui-pdp-breadcrumb')\n",
    "            #data_top = data_top.find('ol', class_ = 'andes-breadcrumb')\n",
    "\n",
    "            data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "            categories_list = []\n",
    "            \n",
    "\n",
    "            for cat in data_top:\n",
    "\n",
    "                categories_list.append(cat.text)\n",
    "        except:\n",
    "             categories_list = []\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mercado_notebbok = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_notebbok = extrai_valor_parcelas(df_mercado_notebbok)\n",
    "df_mercado_notebbok.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_notebbok['Qtde avaliações:'] = df_mercado_notebbok['Qtde avaliações:'].apply(lambda x: x if x == '' else int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_notebbok['Preço'] = df_mercado_notebbok['Preço'].apply(lambda x: float(x.replace('R$', '').replace('.', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\notebook_mercadolivre.xlsx'\n",
    "df_mercado_notebbok.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/meias#D[A:meias]\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_49_AGE*GROUP_6725189_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_49_AGE*GROUP_6725189_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_49_AGE*GROUP_6725189_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_49_AGE*GROUP_6725189_NoIndex_True\n"
     ]
    }
   ],
   "source": [
    "## Primeira Página\n",
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'meias'\n",
    "search_url = f\"{base_url}{item}#D[A:{item}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        product_juros = ''\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        product_discount = ''\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    \n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n",
    "\n",
    "## Páginas seguintes\n",
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/meias_Desde_{n}_AGE*GROUP_6725189_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)\n",
    "## Tratamento\n",
    "df_mercado_meias = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_meias = extrai_valor_parcelas(df_mercado_meias)\n",
    "df_mercado_meias.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_meias['Qtde avaliações:'] = df_mercado_meias['Qtde avaliações:'].apply(lambda x: x if x == '' else int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_meias['Preço'] = df_mercado_meias['Preço'].apply(lambda x: float(x.replace('R$', '').replace('.', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\meias_mercadolivre.xlsx'\n",
    "df_mercado_meias.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kit de meias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n",
      "Erro ao acessar a URL: https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_49_NoIndex_True\n"
     ]
    }
   ],
   "source": [
    "## Primeira Página\n",
    "base_url = \"https://lista.mercadolivre.com.br/\"\n",
    "item = 'kit de meias'\n",
    "\n",
    "search_url = f\"{base_url}{item.replace(' ', '-')}#D[A:{item.replace(' ', '%20')}]\"\n",
    "\n",
    "\n",
    "# Realiza a requisição HTTP\n",
    "response = requests.get(search_url)\n",
    "\n",
    "# Verifica se a requisição foi bem-sucedida\n",
    "if response.status_code != 200:\n",
    "    print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "# Parsing do HTML\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Encontra os elementos que contêm as informações do produto\n",
    "products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "# Lista para armazenar os dados dos produtos\n",
    "products_data = []\n",
    "\n",
    "products_data_patr = []\n",
    "\n",
    "\n",
    "# produtos patrocinados\n",
    "products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(products_patr)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products_patr[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products_patr[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products_patr[i].find('span', class_='ui-search-reviews__rating-number')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products_patr[i].find('span', class_='ui-search-reviews__amount').text\n",
    "    except:\n",
    "        product_qt_eval = ''\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products_patr[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        product_fret = ''    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products_patr[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products_patr[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        product_juros = ''\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products_patr[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        product_discount = ''\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products_patr[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "#CATEGORIAS\n",
    "##########################################\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "    \n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df_patr = pd.DataFrame(products_data_patr)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "# Produtos nao patrocinados\n",
    "\n",
    "for i in range(len(products)):\n",
    "\n",
    "    \n",
    "    # Obtém o nome do produto\n",
    "    product_name = products[i].find('h2', class_='ui-search-item__title').text.strip()\n",
    "    \n",
    "    # Obtém o preço do produto\n",
    "    product_price = products[i].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "    try:\n",
    "    # avaliação\n",
    "        product_eval = products[i].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # qtde avaliações\n",
    "        product_qt_eval = products[i].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #frete gratis\n",
    "    try:\n",
    "        product_fret = products[i].find('span', class_='ui-pb-highlight').text.strip()\n",
    "    except:\n",
    "        pass    \n",
    "\n",
    "    try: \n",
    "        # parcelas\n",
    "        product_parc = products[i].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "        # Extrai o texto do elemento\n",
    "        product_parc = product_parc.get_text(strip=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # sem juros    \n",
    "    try:\n",
    "        product_juros = products[i].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "        product_juros = product_juros.find(text='juros')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        # desconto\n",
    "    try:\n",
    "        product_discount = products[i].find('span', class_='ui-search-price__discount').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #link\n",
    "    product_link = products[i].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "    # Extrai o atributo href do elemento\n",
    "    product_link = product_link['href']\n",
    "\n",
    "\n",
    "    # DADOS LINK\n",
    "\n",
    "    response2 = requests.get(product_link)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response2.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "    # Nome vendedor\n",
    "    try:\n",
    "        #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "        #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "        info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "        # Extrai o vendedor \n",
    "        seller = info_element.text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # posição de venda na categoria, se possui\n",
    "    try:\n",
    "\n",
    "        #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "        position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "        position = position[1].text\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try:\n",
    "    # Novo/usado e qtde vendida\n",
    "        #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "        situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "        # Separa as informações 'Novo' e '+500 vendidos'\n",
    "        info_parts = situation.text.split('|')\n",
    "\n",
    "        # Remove os espaços em branco ao redor de cada parte\n",
    "        info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "        product_situation = info_parts[0]\n",
    "        product_sells = info_parts[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "        # Quant. de fotos\n",
    "    try:\n",
    "        # qtde fotos\n",
    "        #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "        #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "        #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "        images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "        images = len(images)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "    categories_list = []\n",
    "    \n",
    "\n",
    "    for cat in data_top:\n",
    "\n",
    "        cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "        categories_list.append(cat['title'])\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "    # Adiciona os dados do produto à lista\n",
    "    # Adiciona os dados do produto à lista\n",
    "    products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "# Cria um DataFrame com os dados dos produtos\n",
    "df = pd.DataFrame(products_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Páginas seguintes\n",
    "# DataFrame vazio para armazenar todos os dados um para patrocinados e outro não patrocinado\n",
    "all_products_df = pd.DataFrame()\n",
    "all_products_df_patr = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 5):\n",
    "    n = 49 \n",
    "    search_url = f'https://lista.mercadolivre.com.br/calcados-roupas-bolsas/moda-intima-lingerie/roupa-intima/meias-meia-calcas/meias/kit-de-meias_Desde_{49}_NoIndex_True'\n",
    "\n",
    "    # Realiza a requisição HTTP\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    # Verifica se a requisição foi bem-sucedida\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "        continue\n",
    "\n",
    "    # Parsing do HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Lista para armazenar os dados dos produtos desta iteração\n",
    "    products_data = []\n",
    "\n",
    "    # Encontra os elementos que contêm as informações do produto\n",
    "    products = soup.find_all(class_='ui-search-result__content-wrapper')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    all_products_data_patr = []\n",
    "\n",
    "\n",
    "    # produtos patrocinados\n",
    "    products_patr = soup.find(class_='ui-search-layout ui-search-layout--grid')\n",
    "    products_patr= products_patr.find_all('li', class_='ui-search-layout__item')\n",
    "\n",
    "    for x in range(len(products_patr)):\n",
    "\n",
    "        \n",
    "        # Obtém o nome do produto\n",
    "        product_name = products_patr[x].find('h2', class_='ui-search-item__title').text.strip()\n",
    "        \n",
    "        # Obtém o preço do produto\n",
    "        product_price = products_patr[x].find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "        try:\n",
    "        # avaliação\n",
    "            product_eval = products_patr[x].find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = products_patr[x].find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = products_patr[x].find('span', class_='ui-pb-highlight')\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "        try: \n",
    "            # parcelas\n",
    "            product_parc = products_patr[x].find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products_patr[x].find('div', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            # desconto\n",
    "        try:\n",
    "            product_discount = products_patr[x].find('span', class_='ui-search-price__discount')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #link\n",
    "        product_link = products_patr[x].find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "\n",
    "        # Nome vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR')\n",
    "\n",
    "            # Extrai o vendedor \n",
    "            seller = info_element.text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            position = soup2.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = position[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        try:\n",
    "        # Novo/usado e qtde vendida\n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            # qtde fotos\n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "    \n",
    "          \n",
    "    \n",
    "\n",
    "        \n",
    "        # Adiciona os dados do produto à lista\n",
    "        all_products_data_patr.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    # Cria um DataFrame com os dados dos produtos\n",
    "\n",
    "    patr_temp_df = pd.DataFrame(all_products_data_patr)\n",
    "    all_products_df_patr = pd.concat([all_products_df_patr, patr_temp_df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for product in products:\n",
    "        # Obtém o nome do produto\n",
    "        product_name = product.find('h2', class_='ui-search-item__title').text.strip()\n",
    "\n",
    "        # Obtém o preço do produto\n",
    "        product_price = product.find('span', class_='andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript').text.strip()\n",
    "\n",
    "\n",
    "        try:\n",
    "    # avaliação\n",
    "            product_eval = product.find('span', class_='ui-search-reviews__rating-number').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "        # qtde avaliações\n",
    "            product_qt_eval = product.find('span', class_='ui-search-reviews__amount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #frete gratis\n",
    "        try:\n",
    "            product_fret = product.find('span', class_='ui-pb-highlight').text.strip()\n",
    "        except:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        try: \n",
    "        # parcelas\n",
    "            product_parc = product.find('span', class_='ui-search-item__group__element ui-search-installments ui-search-color--BLACK')\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            product_parc = product_parc.get_text(strip=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # sem juros    \n",
    "        try:\n",
    "            product_juros = products.find('span', class_='ui-search-price ui-search-price--size-x-tiny ui-search-color--LIGHT_GREEN')\n",
    "            product_juros = product_juros.find(text='juros')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        # desconto\n",
    "        try:\n",
    "            product_discount = product.find('span', class_='ui-search-price__discount').text.strip()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        #link\n",
    "        product_link = product.find('a', class_='ui-search-item__group__element ui-search-link__title-card ui-search-link')\n",
    "\n",
    "        # Extrai o atributo href do elemento\n",
    "        product_link = product_link['href']\n",
    "\n",
    "\n",
    "        # DADOS LINK\n",
    "\n",
    "        response2 = requests.get(product_link)\n",
    "\n",
    "        # Verifica se a requisição foi bem-sucedida\n",
    "        if response2.status_code != 200:\n",
    "            print(f\"Erro ao acessar a URL: {search_url}\")\n",
    "\n",
    "        # Parsing do HTML\n",
    "        soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        # Vendedor\n",
    "        try:\n",
    "            #info_element = soup2.find('div', class_='ui-pdp-container__row ui-pdp--relative ui-pdp-with--separator--fluid pb-40')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp--sticky-wrapper ui-pdp--sticky-wrapper-right')\n",
    "            #info_element = info_element.find('div',class_ = 'ui-pdp-seller mb-20 mt-20 ui-pdp-seller__with-logo')\n",
    "            info_element = soup2.find('span',class_ = 'ui-pdp-color--BLUE ui-pdp-family--REGULAR').text\n",
    "\n",
    "            # Extrai o texto do elemento\n",
    "            seller = info_element\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        # posição de venda na categoria, se possui\n",
    "        try:\n",
    "\n",
    "            #position = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            #position = position.find('div',class_ = 'ui-pdp-promotions-pill mt-10 ui-pdp-highlights')\n",
    "            #position = position.find_all('a',class_ = 'ui-pdp-promotions-pill-label__target')\n",
    "            position = soup2[1].text\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Novo/usado e qtde vendida\n",
    "        try:\n",
    "        \n",
    "            #situation = soup2.find('div', class_='ui-pdp-container__col col-2 mr-32')\n",
    "            situation = soup2.find('div',class_ = 'ui-pdp-header__subtitle')\n",
    "\n",
    "\n",
    "            # Separa as informações 'Novo' e '+500 vendidos'\n",
    "            info_parts = situation.text.split('|')\n",
    "\n",
    "            # Remove os espaços em branco ao redor de cada parte\n",
    "            info_parts = [part.strip() for part in info_parts]\n",
    "\n",
    "            product_situation = info_parts[0]\n",
    "            product_sells = info_parts[1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "            # Quant. de fotos\n",
    "        try:\n",
    "            \n",
    "            #images = soup2.find('div', class_='ui-pdp-container__row ui-pdp-with--separator--fluid ui-pdp-with--separator--40')\n",
    "            #images = images.find('div',class_ = 'ui-pdp-container__col col-2 ui-pdp--relative')\n",
    "\n",
    "            #images= images.find('div',class_ = 'ui-pdp-gallery__column')\n",
    "            images = soup2.find_all('span',class_ = 'ui-pdp-gallery__wrapper')\n",
    "\n",
    "            images = len(images)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "        data_top = soup2.find_all('li',class_ = 'andes-breadcrumb__item')\n",
    "\n",
    "        categories_list = []\n",
    "        \n",
    "\n",
    "        for cat in data_top:\n",
    "\n",
    "            cat = cat.find('a', class_ = 'andes-breadcrumb__link')\n",
    "            categories_list.append(cat['title'])\n",
    "\n",
    "    \n",
    "###############################################\n",
    "\n",
    "        # Adiciona os dados do produto à lista\n",
    "        products_data.append({'Nome do Produto': product_name, 'Preço': product_price, 'Patrocinado': 'sim', \n",
    "                          'Avaliação': product_eval, 'Qtde avaliações:': product_qt_eval,'Parcelas': product_parc, \n",
    "                          'Desconto': product_discount,'Frete': product_fret, 'Link': product_link, 'Vendedor': seller, \n",
    "                          'Posição': position, 'Situação': product_situation, 'Quant. vendida': product_sells, \n",
    "                          'Categorias': categories_list,'Quant. fotos': images})\n",
    "\n",
    "    n = n + 48\n",
    "    # Cria um DataFrame temporário com os dados dos produtos desta iteração\n",
    "    temp_df = pd.DataFrame(products_data)\n",
    "\n",
    "    # Concatena o DataFrame temporário ao DataFrame principal\n",
    "    all_products_df = pd.concat([all_products_df, temp_df], ignore_index=True)\n",
    "## Tratamento\n",
    "df_mercado_kitmeias = pd.concat([df, df_patr,all_products_df_patr,all_products_df], join = 'outer')\n",
    "df_mercado_kitmeias = extrai_valor_parcelas(df_mercado_kitmeias)\n",
    "df_mercado_kitmeias.drop(['Parcelas'], axis = 1, inplace = True)\n",
    "# removendo os parenteses das avaliações e convertendo o número para inteiro\n",
    "df_mercado_kitmeias['Qtde avaliações:'] = df_mercado_kitmeias['Qtde avaliações:'].apply(lambda x: x if x == '' else int(x.replace('(', '').replace(')','')))\n",
    "# convertendo o preço para número decimal\n",
    "df_mercado_kitmeias['Preço'] = df_mercado_kitmeias['Preço'].apply(lambda x: float(x.replace('R$', '').replace('.', '').replace(',', '.')))\n",
    "\n",
    "caminho = f'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\kitmeias_mercadolivre.xlsx'\n",
    "df_mercado_kitmeias.to_excel(caminho, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prpau\\AppData\\Local\\Temp\\ipykernel_11020\\656822717.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_geral[f'Categoria{x}'].iloc[i] = df_geral['Categorias'].iloc[i][x]\n"
     ]
    }
   ],
   "source": [
    "df_mercado_brinquedo['Categoria'] = 'Brinquedo'\n",
    "df_mercado_escritorio['Categoria'] = \"Escritório\"\n",
    "df_mercado_mochila['Categoria'] = 'Mochila'\n",
    "df_mercado_papelaria['Categoria'] = 'Papelaria'\n",
    "df_mercado_pc['Categoria'] = 'PC'\n",
    "df_mercado_notebbok['Categoria'] = 'Notebook'\n",
    "df_mercado_meias['Categoria'] = 'Meias'\n",
    "df_mercado_kitmeias['Categoria'] = 'Kit Meias'\n",
    "\n",
    "df_geral = pd.concat([df_mercado_brinquedo, df_mercado_escritorio, df_mercado_mochila, \n",
    "                      df_mercado_papelaria, df_mercado_pc, df_mercado_notebbok,df_mercado_meias, df_mercado_kitmeias ], join = 'outer')\n",
    "\n",
    "\n",
    "df_geral['Categoria0'] = 0\n",
    "df_geral['Categoria1'] = 0\n",
    "df_geral['Categoria2'] = 0\n",
    "df_geral['Categoria3'] = 0\n",
    "df_geral['Categoria4'] = 0\n",
    "df_geral['Categoria5'] = 0\n",
    "df_geral['Categoria6'] = 0\n",
    "\n",
    "for i in range(len(df_geral['Categorias'])):\n",
    "\n",
    "    for x in range(len(df_geral['Categorias'].iloc[i])):\n",
    "        df_geral[f'Categoria{x}'].iloc[i] = df_geral['Categorias'].iloc[i][x]\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Categoria-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\prpau\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\prpau\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\prpau\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categoria-1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m7\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m df_geral[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCategoria\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[i] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         df_geral[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCategoria\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[i] \u001b[39m=\u001b[39m df_geral[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCategoria\u001b[39;49m\u001b[39m{\u001b[39;49;00mx\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39miloc[i]\n",
      "File \u001b[1;32mc:\\Users\\prpau\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\prpau\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Categoria-1'"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_geral['Categorias'])):\n",
    "\n",
    "        for x in range(0,7):\n",
    "            if df_geral[f'Categoria{x}'].iloc[i] == 0:\n",
    "                df_geral[f'Categoria{x}'].iloc[i] = df_geral[f'Categoria{x-1}'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho = 'C:\\\\Users\\\\prpau\\\\Documents\\\\webscraping_helpseller\\\\mercadolivre_atualizado.xlsx'\n",
    "df_geral.to_excel(caminho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4ff7311eafac93b92f21d9a2329e46afd84871b50c290fea5610f23becc04a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
